# sandbox-llm
A small LLM interface designed for sandboxed clients 

# Tech stack

1. TheBloke GGUF quantized model
2. llama.cpp for interface calls
3. 

# Requirements
```
python 3.8+
```

# Setup

## Download model
```

wget -P models https://huggingface.co/TheBloke/Mistral-7B-v0.1-GGUF/resolve/main/mistral-7b-v0.1.Q4_K_M.gguf
```
